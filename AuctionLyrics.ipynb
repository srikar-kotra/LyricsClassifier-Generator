{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPvaq6x/8tjoiactJjh9tvO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srikar-kotra/LyricsClassifier-Generator/blob/main/AuctionLyrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4Rf08EhdXwxX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ytG86j2ZX2PC",
        "outputId": "9994ffd9-6822-4912-b836-625aacd118c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8af29389-e93a-4653-bcb7-e66c3441da71\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8af29389-e93a-4653-bcb7-e66c3441da71\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Book1.csv to Book1.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = 'Book1.csv'\n",
        "spotify_data = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "p_DTpr_NX4Hx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "# Clean the lyrics data\n",
        "spotify_data['clean_lyrics'] = spotify_data['text'].str.replace('[^a-zA-Z\\s]', '', regex=True).str.lower()\n",
        "\n",
        "\n",
        "# Tokenize the lyrics using numpy\n",
        "spotify_data['tokenized_lyrics'] = spotify_data['clean_lyrics'].apply(lambda x: np.array(x.split()))\n",
        "\n",
        "# Remove stop words (assuming 'stop_words' a list of stop words)\n",
        "stop_words = ['a', 'an', 'the', 'is', 'of', 'and', 'it']  # Define the stop words\n",
        "spotify_data['filtered_lyrics'] = spotify_data['tokenized_lyrics'].apply(lambda x: np.array([word for word in x if word not in stop_words]))"
      ],
      "metadata": {
        "id": "9iWs55irY3X2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis using a custom approach\n",
        "# Define your own sentiment scoring system using numpy\n",
        "# This could involve counting positive and negative words, or using other custom rules\n",
        "\n",
        "# For example, defining a simple sentiment score based on the presence of certain words\n",
        "# Positive Words# Positive Words\n",
        "positive_words = ['love', 'joy', 'happy', 'sun', 'dream', 'free', 'happiness', 'dream', 'hope', 'laugh']\n",
        "\n",
        "# Negative Words\n",
        "negative_words = ['heartbreak', 'pain', 'tears', 'sad', 'lonely', 'dark', 'angry', 'hate', 'death', 'die']\n",
        "\n",
        "# Function to calculate sentiment score\n",
        "def calculate_sentiment_score(words):\n",
        "    positive_score = np.sum([word in positive_words for word in words])\n",
        "    negative_score = np.sum([word in negative_words for word in words])\n",
        "    total_score = positive_score - negative_score\n",
        "    return total_score\n",
        "\n",
        "# Apply sentiment scoring\n",
        "spotify_data['sentiment_score'] = spotify_data['filtered_lyrics'].apply(lambda x: calculate_sentiment_score(x))\n",
        "\n",
        "# Map sentiment scores to mood categories\n",
        "def classify_mood(score):\n",
        "    if score > 0:\n",
        "        return 'Happy'\n",
        "    elif score < 0:\n",
        "        return 'Sad'\n",
        "    else:\n",
        "        return 'Neutral'\n",
        "\n",
        "spotify_data['mood_category'] = spotify_data['sentiment_score'].apply(classify_mood)\n",
        "print(spotify_data[['song', 'mood_category']])\n",
        "\n",
        "# Now you can move on to deploying your model and using it to predict the mood of songs based on their lyrics."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSMkhcXKY7g1",
        "outputId": "a8a0ac5f-828c-466e-f52c-e2047d18c3a6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             song mood_category\n",
            "0             Belong To The World         Happy\n",
            "1                     False Alarm         Happy\n",
            "2                        Live For           Sad\n",
            "3                        The Town         Happy\n",
            "4                      Acquainted         Happy\n",
            "5                           Angel         Happy\n",
            "6                      As You Are         Happy\n",
            "7              Can't Feel My Face         Happy\n",
            "8                   Devil May Cry       Neutral\n",
            "9                       Earned It         Happy\n",
            "10                          Enemy         Happy\n",
            "11            Heaven Or Las Vegas       Neutral\n",
            "12                  High For This         Happy\n",
            "13             Can't Feel My Face         Happy\n",
            "14                   In The Night           Sad\n",
            "15                         Losers         Happy\n",
            "16                          Often         Happy\n",
            "17               Pass Dat (Remix)       Neutral\n",
            "18                      Real Life       Neutral\n",
            "19                      Shameless           Sad\n",
            "20              Tell Your Friends         Happy\n",
            "21               The Birds Part 1         Happy\n",
            "22                      The Hills         Happy\n",
            "23  The Hills (Nicki Minaj Remix)         Happy\n",
            "24                    The Knowing       Neutral\n",
            "25                       Thursday         Happy\n",
            "26                        Valerie         Happy\n",
            "27                  What You Need         Happy\n",
            "28                   Wicked Games         Happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first few rows of the dataset\n",
        "print(spotify_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avR9pck1b2rE",
        "outputId": "1343beba-c609-47b9-e463-4d3f306f4e0a"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       artist                 song  \\\n",
            "0  The Weeknd  Belong To The World   \n",
            "1  The Weeknd          False Alarm   \n",
            "2  The Weeknd             Live For   \n",
            "3  The Weeknd             The Town   \n",
            "4  The Weeknd           Acquainted   \n",
            "\n",
            "                                              link  \\\n",
            "0  /t/the+weeknd/belong+to+the+world_21065400.html   \n",
            "1          /t/the+weeknd/false+alarm_21111264.html   \n",
            "2             /t/the+weeknd/live+for_21067397.html   \n",
            "3             /t/the+weeknd/the+town_21067482.html   \n",
            "4           /t/the+weeknd/acquainted_21102482.html   \n",
            "\n",
            "                                                text  \\\n",
            "0  I know you want your money, girl  \\n'Cause you...   \n",
            "1  [Verse 1]  \\nBathroom stalls for the powder no...   \n",
            "2  Getting sober for a day, got me feeling too lo...   \n",
            "3  You did many things  \\nThat I liked, that I li...   \n",
            "4  [Verse 1]  \\nBaby you smell good  \\nCause they...   \n",
            "\n",
            "                                        clean_lyrics  \\\n",
            "0  i know you want your money girl  \\ncause you d...   \n",
            "1  verse   \\nbathroom stalls for the powder nose ...   \n",
            "2  getting sober for a day got me feeling too low...   \n",
            "3  you did many things  \\nthat i liked that i lik...   \n",
            "4  verse   \\nbaby you smell good  \\ncause they wa...   \n",
            "\n",
            "                                    tokenized_lyrics  \\\n",
            "0  [i, know, you, want, your, money, girl, cause,...   \n",
            "1  [verse, bathroom, stalls, for, the, powder, no...   \n",
            "2  [getting, sober, for, a, day, got, me, feeling...   \n",
            "3  [you, did, many, things, that, i, liked, that,...   \n",
            "4  [verse, baby, you, smell, good, cause, they, w...   \n",
            "\n",
            "                                     filtered_lyrics  sentiment_score  \\\n",
            "0  [i, know, you, want, your, money, girl, cause,...                7   \n",
            "1  [verse, bathroom, stalls, for, powder, nose, s...                1   \n",
            "2  [getting, sober, for, day, got, me, feeling, t...               -9   \n",
            "3  [you, did, many, things, that, i, liked, that,...                6   \n",
            "4  [verse, baby, you, smell, good, cause, they, w...                3   \n",
            "\n",
            "  mood_category  \n",
            "0         Happy  \n",
            "1         Happy  \n",
            "2           Sad  \n",
            "3         Happy  \n",
            "4         Happy  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target variable (y)\n",
        "X = spotify_data['filtered_lyrics']\n",
        "y = spotify_data['mood_category']"
      ],
      "metadata": {
        "id": "FTgzgyujd2E2"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets without sklearn\n",
        "mask = np.random.rand(len(spotify_data)) < 0.8\n",
        "train_data = spotify_data[mask]\n",
        "test_data = spotify_data[~mask]"
      ],
      "metadata": {
        "id": "pnmFqLg2fCio"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features (X) and target variable (y)\n",
        "X_train = train_data['filtered_lyrics']\n",
        "y_train = train_data['mood_category']\n",
        "X_test = test_data['filtered_lyrics']\n",
        "y_test = test_data['mood_category']"
      ],
      "metadata": {
        "id": "W4k8nU5gfE2n"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_words = np.unique(np.hstack(X_train.apply(lambda x: np.unique(x)).values))\n",
        "\n",
        "# Create a dictionary mapping each unique word to its index\n",
        "word_to_index = {word: idx for idx, word in enumerate(unique_words)}\n"
      ],
      "metadata": {
        "id": "Sr8A_ax1fICa"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, word_to_index):\n",
        "    vector = np.zeros(len(word_to_index))\n",
        "    for word in text:\n",
        "        if word in word_to_index:\n",
        "            vector[word_to_index[word]] += 1\n",
        "    return vector\n",
        "\n",
        "X_train_vectorized = np.array([vectorize_text(text, word_to_index) for text in X_train])\n",
        "X_test_vectorized = np.array([vectorize_text(text, word_to_index) for text in X_test])"
      ],
      "metadata": {
        "id": "ZGxfqeNql9XD"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultinomialNB:\n",
        "    def __init__(self):\n",
        "        self.class_probs = {}\n",
        "        self.word_probs = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        unique_classes, class_counts = np.unique(y, return_counts=True)\n",
        "        total_samples = len(y)\n",
        "\n",
        "        for cls, count in zip(unique_classes, class_counts):\n",
        "            self.class_probs[cls] = count / total_samples\n",
        "\n",
        "        for cls in unique_classes:\n",
        "            cls_indices = np.where(y == cls)\n",
        "            cls_texts = X[cls_indices]\n",
        "            total_words_in_cls = np.sum(cls_texts)\n",
        "            self.word_probs[cls] = np.sum(cls_texts, axis=0) / total_words_in_cls\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "\n",
        "        for text in X:\n",
        "            scores = {}\n",
        "\n",
        "            for cls in self.class_probs:\n",
        "                score = np.log(self.class_probs[cls])\n",
        "                score += np.sum(np.log(self.word_probs[cls] + 1) * text)\n",
        "                scores[cls] = score\n",
        "\n",
        "            predicted_class = max(scores, key=scores.get)\n",
        "            predictions.append(predicted_class)\n",
        "\n",
        "        return np.array(predictions)"
      ],
      "metadata": {
        "id": "gdkQVHDCfV1t"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate and fit the classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train_vectorized, y_train)"
      ],
      "metadata": {
        "id": "D2waUcetrok9"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = classifier.predict(X_test_vectorized)\n"
      ],
      "metadata": {
        "id": "QDNM1DdFrqIB"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    correct = np.sum(y_true == y_pred)\n",
        "    total = len(y_true)\n",
        "    return correct / total\n",
        "\n",
        "def precision_recall_f1(y_true, y_pred):\n",
        "    unique_classes = np.unique(np.concatenate([y_true, y_pred]))\n",
        "    metrics = {}\n",
        "\n",
        "    for cls in unique_classes:\n",
        "        true_positive = np.sum((y_true == cls) & (y_pred == cls))\n",
        "        false_positive = np.sum((y_true != cls) & (y_pred == cls))\n",
        "        false_negative = np.sum((y_true == cls) & (y_pred != cls))\n",
        "\n",
        "        precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
        "        recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
        "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "        metrics[cls] = {'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
        "\n",
        "    return metrics\n",
        "\n",
        "print(\"Accuracy:\", accuracy(y_test.values, y_pred))\n",
        "print(\"Classification Report:\\n\", precision_recall_f1(y_test.values, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV5jbQj-rtXn",
        "outputId": "91fe03ee-e74c-4456-dd14-c37490fc892b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8333333333333334\n",
            "Classification Report:\n",
            " {'Happy': {'Precision': 0.8333333333333334, 'Recall': 1.0, 'F1 Score': 0.9090909090909091}, 'Neutral': {'Precision': 0, 'Recall': 0.0, 'F1 Score': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define a function to generate lyrics based on mood\n",
        "def generate_lyrics_randomly(vocabulary, num_words=50):\n",
        "    # Randomly sample words from the vocabulary to generate lyrics\n",
        "    generated_lyrics = ' '.join(random.sample(vocabulary, min(num_words, len(vocabulary))))\n",
        "\n",
        "    return generated_lyrics\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have the vocabulary from the dataset\n",
        "vocabulary = set(word for lyrics in spotify_data['filtered_lyrics'] for word in lyrics)\n",
        "\n",
        "mood_to_generate = 'Happy'\n",
        "generated_lyrics = generate_lyrics_randomly(vocabulary)\n",
        "print(f\"Generated Lyrics for {mood_to_generate} mood:\\n\", generated_lyrics)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSpDEk8YugA1",
        "outputId": "b1ca3f8c-8903-4ea0-c86b-86e1a2817701"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Lyrics for Happy mood:\n",
            " day another myself lovin rode nothin come dancing half obsessed plenty warn their threesome while down responsibility want scars liked knee doubt gon coat have oh because guess put lens feel havent them double gonna conversation close stupids scream motherfucking almost said racist eighth point eyes old king control think\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-68-b692770bab6b>:6: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  generated_lyrics = ' '.join(random.sample(vocabulary, min(num_words, len(vocabulary))))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9urFIWIFfhYH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}